{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/ocean/projects/asc170022p/shg121/PhD/Project_Pruning\"))\n",
    "import h5py\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import lth_pruning.pruning_utils as prune_utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import utils\n",
    "from model_factory.models import Classifier\n",
    "from model_factory.model_meta import Model_Meta\n",
    "from dataset.dataset_utils import get_dataset_with_attributes, get_transforms\n",
    "from dataset.dataset_attributes_mnist import Dataset_attributes_mnist\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "device = utils.get_device()\n",
    "print(f\"Device: {device}\")\n",
    "data_root = \"/ocean/projects/asc170022p/shg121/PhD/Project_Pruning/data/MNIST_EVEN_ODD\"\n",
    "json_root = \"/ocean/projects/asc170022p/shg121/PhD/Project_Pruning/scripts_data\"\n",
    "model_arch = \"Resnet_18\"\n",
    "dataset_name = \"mnist\"\n",
    "pretrained = True\n",
    "transfer_learning = False\n",
    "chk_pt_path = \"seq_epoch_20.pth.tar\"\n",
    "num_classes = 1\n",
    "logs = \"/ocean/projects/asc170022p/shg121/PhD/Project_Pruning/Results\"\n",
    "bb_layer = \"layer3\"  # layer3\n",
    "concept_names = [\"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\"]\n",
    "img_size = 224\n",
    "batch_size = 3\n",
    "epochs = 50\n",
    "num_workers = 4\n",
    "class_list = [0, 1]\n",
    "num_labels = len(class_list)\n",
    "cav_vector_file = \"max_pooled_train_cavs.pkl\"\n",
    "kernel_size={\n",
    "    \"layer3\": 14,\n",
    "    \"layer4\": 7\n",
    "}\n",
    "\n",
    "prune_type = \"lt\"\n",
    "lr = 1e-3\n",
    "ITERATION  = 35\n",
    "prune_percent = 10\n",
    "start_iter = 0\n",
    "end_iter = 100\n",
    "resample = False\n",
    "reinit = True if prune_type==\"reinit\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the [test] dataset: 60000\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1523ab27eb50>\n"
     ]
    }
   ],
   "source": [
    "import lth_pruning.pruning_utils as pruning_utils\n",
    "transform_params = {\n",
    "        \"img_size\": img_size\n",
    "    }\n",
    "test_loader = pruning_utils.get_test_dataloader(\n",
    "        \"mnist\",\n",
    "        \"/ocean/projects/asc170022p/shg121/PhD/Project_Pruning/data/MNIST_EVEN_ODD\",\n",
    "        json_root,\n",
    "        1,\n",
    "        transform_params\n",
    "    )\n",
    "\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BB Model loaded from:\n",
      "/ocean/projects/asc170022p/shg121/PhD/Project_Pruning/Results/chk_pt/Pruning/Resnet_18/mnist/best_val_prune_iteration_3_model_lt.pth.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/ocean/projects/asc170022p/shg121/PhD/Project_Pruning/Results/chk_pt/Pruning/Resnet_18/mnist\"\n",
    "model = Classifier(model_arch, num_classes,  \"mnist\", pretrained, transfer_learning)\n",
    "model.to(device)\n",
    "chk_pt_file = f\"best_val_prune_iteration_3_model_lt.pth.tar\"\n",
    "chk_pt_file_name = os.path.join(checkpoint_path, chk_pt_file)\n",
    "print(\"BB Model loaded from:\")\n",
    "print(os.path.join(checkpoint_path, chk_pt_file))\n",
    "model_chk_pt = torch.load(chk_pt_file_name)\n",
    "model.load_state_dict(model_chk_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [05:28<00:00, 182.39it/s, batch_id=59999]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out_put_predict_bb = torch.FloatTensor().cuda()\n",
    "out_put_GT = torch.FloatTensor().cuda()\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_loader)) as t:\n",
    "        for batch_id, (images, labels) in enumerate(test_loader):\n",
    "            bs = images.size(0)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.reshape((labels.shape[0], 1))\n",
    "            input_to_pred = model(images)\n",
    "            \n",
    "            bs = images.size(0)\n",
    "            input_to_pred = model(images)\n",
    "            out_put_predict_bb = torch.cat((out_put_predict_bb, input_to_pred), dim=0)\n",
    "            out_put_GT = torch.cat((out_put_GT, labels), dim=0)\n",
    "            \n",
    "            t.set_postfix(batch_id='{0}'.format(batch_id))\n",
    "            t.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30508., device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.6405259e-04],\n",
       "       [2.3663255e-04],\n",
       "       [7.7274498e-03],\n",
       "       ...,\n",
       "       [9.9996352e-01],\n",
       "       [9.4752026e-01],\n",
       "       [9.3911374e-01]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out_put_GT[out_put_GT>0.5].sum())\n",
    "out_put_predict_bb.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1769520000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_acc = utils.get_correct(out_put_predict_bb.cpu(), out_put_GT.cpu(), num_labels) \n",
    "bb_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58882"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = out_put_predict_bb.cpu()\n",
    "y = out_put_GT.cpu()\n",
    "y_hat = [1 if y_hat[i] >= 0.5 else 0 for i in range(len(y_hat))]\n",
    "correct = [1 if y_hat[i] == y[i] else 0 for i in range(len(y_hat))]\n",
    "tot_correct = np.sum(correct)\n",
    "tot_correct/60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the [test] dataset: 60000\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataset_utils import get_dataset, get_transforms\n",
    "from dataset.dataset_mnist import Dataset_mnist\n",
    "test_set = get_dataset(\n",
    "    data_root=data_root,\n",
    "    json_root=json_root,\n",
    "    dataset_name=dataset_name,\n",
    "    mode=\"test\"\n",
    ")\n",
    "\n",
    "transform = get_transforms(size=img_size)\n",
    "test_dataset = Dataset_mnist(test_set, transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "device = utils.get_device()\n",
    "print(f\"Device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the [test] dataset: 60000\n"
     ]
    }
   ],
   "source": [
    "transform_params = {\n",
    "        \"img_size\": img_size\n",
    "    }\n",
    "start = time.time()\n",
    "test_data_loader = pruning_utils.get_test_dataloader(\n",
    "        dataset_name,\n",
    "        data_root,\n",
    "        json_root,\n",
    "        batch_size,\n",
    "        transform_params\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:16<00:00, 260.12it/s, batch_id=19999]\n"
     ]
    }
   ],
   "source": [
    "model = Classifier(model_arch, num_classes, dataset_name, pretrained, transfer_learning).to(device)\n",
    "checkpoint_path = \"/ocean/projects/asc170022p/shg121/PhD/Project_Pruning/Results/chk_pt/Pruning/Resnet_18/mnist/best_val_prune_iteration_3_model_lt.pth.tar\"\n",
    "\n",
    "model_chk_pt = torch.load(checkpoint_path)\n",
    "model.load_state_dict(model_chk_pt)\n",
    "model.eval()\n",
    "\n",
    "out_put_GT = torch.FloatTensor().cuda()\n",
    "out_put_predict = torch.FloatTensor().cuda()\n",
    "out_prob_arr = []\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_loader)) as t:\n",
    "        for batch_id, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.reshape((labels.shape[0], 1))\n",
    "            y_hat = model(images)\n",
    "            out_prob_arr.append(y_hat)\n",
    "            out_put_predict = torch.cat((out_put_predict, y_hat), dim=0)\n",
    "            out_put_GT = torch.cat((out_put_GT, labels), dim=0)\n",
    "            t.set_postfix(batch_id='{0}'.format(batch_id))\n",
    "            t.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0343],\n",
       "        [0.0020],\n",
       "        [0.0103],\n",
       "        ...,\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [0.9996]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_put_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9813666666666667\n",
      "Precision: 0.9867828276136213\n",
      "Recall: 0.9764324111708405\n",
      "RocAUC: 0.9814516592677748\n",
      "F1 score: 0.9815803347831817\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = utils.get_correct(out_put_predict, out_put_GT, 1) / out_put_GT.size(0)\n",
    "out_put_GT_np = out_put_GT.cpu().numpy()\n",
    "out_put_predict_np = out_put_predict.cpu().numpy()\n",
    "y_hat = np.where(out_put_predict_np > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {utils.cal_accuracy(out_put_GT_np, y_hat)}\")\n",
    "print(f\"Precision: {utils.cal_precision(out_put_GT_np, y_hat)}\")\n",
    "print(f\"Recall: {utils.cal_recall(out_put_GT_np, y_hat)}\")\n",
    "print(f\"RocAUC: {utils.cal_roc_auc(out_put_GT_np, y_hat)}\")\n",
    "print(f\"F1 score: {utils.cal_f1_score(out_put_GT_np, y_hat)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [01:17<00:00, 259.05it/s, batch_id=19999]\n"
     ]
    }
   ],
   "source": [
    "model = Classifier(model_arch, num_classes, dataset_name, pretrained, transfer_learning).to(device)\n",
    "checkpoint_path = \"/ocean/projects/asc170022p/shg121/PhD/Project_Pruning/Results/chk_pt/Pruning/Resnet_18/mnist/best_val_prune_iteration_3_model_lt.pth.tar\"\n",
    "\n",
    "model_chk_pt = torch.load(checkpoint_path)\n",
    "model.load_state_dict(model_chk_pt)\n",
    "model.eval()\n",
    "\n",
    "out_put_GT = torch.FloatTensor().cuda()\n",
    "out_put_predict = torch.FloatTensor().cuda()\n",
    "out_prob_arr = []\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_data_loader)) as t:\n",
    "        for batch_id, (images, labels) in enumerate(test_data_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.reshape((labels.shape[0], 1))\n",
    "            y_hat = model(images)\n",
    "            out_prob_arr.append(y_hat)\n",
    "            out_put_predict = torch.cat((out_put_predict, y_hat), dim=0)\n",
    "            out_put_GT = torch.cat((out_put_GT, labels), dim=0)\n",
    "            t.set_postfix(batch_id='{0}'.format(batch_id))\n",
    "            t.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9813666666666667\n",
      "Precision: 0.9867828276136213\n",
      "Recall: 0.9764324111708405\n",
      "RocAUC: 0.9814516592677748\n",
      "F1 score: 0.9815803347831817\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = utils.get_correct(out_put_predict, out_put_GT, 1) / out_put_GT.size(0)\n",
    "out_put_GT_np = out_put_GT.cpu().numpy()\n",
    "out_put_predict_np = out_put_predict.cpu().numpy()\n",
    "y_hat = np.where(out_put_predict_np > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {utils.cal_accuracy(out_put_GT_np, y_hat)}\")\n",
    "print(f\"Precision: {utils.cal_precision(out_put_GT_np, y_hat)}\")\n",
    "print(f\"Recall: {utils.cal_recall(out_put_GT_np, y_hat)}\")\n",
    "print(f\"RocAUC: {utils.cal_roc_auc(out_put_GT_np, y_hat)}\")\n",
    "print(f\"F1 score: {utils.cal_f1_score(out_put_GT_np, y_hat)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3_7",
   "language": "python",
   "name": "python_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
